
1. H264 zero-copy pipeline set up
	1. nvidia library installation
	2. ROS2 C++ Node for testing
2. GPU Inference using deepstream
	1. inference results back to ros2 node
	2. published as a topic
3. ros2_benchmark hello world against above nodes
	1. test before and after using shared memory
4. ros2 node for lidar and camera sensor fusion
5. ros2_benchmark again 
6. Optimize latency and throuput and run perfomance tests
7. Jeson board preparation and deployment test

[ ] iceoryx shared memory  실험 설계 및 결과 작성: 변수, 통제, 메트릭 등.
- 메시지 크기 (1k, 10k, 100k 등) 
- ring count (4, 16, 64) 등
- OS 상태 및 설정 등
- 데이터 타입 및 사이즈 등
- 데이터의 양 및 hertz


ros2_benchmark 자동화 및 산출물 자동 저장 목표
- 회귀 추적이 가능하도록 데이터가 쌓여야 함
- 새로운 결과물이 나올 때 자동으로 비교되도록


1. Container화 해야 함
2. 일단 프로젝트를 단순화시키고, 그걸 완성한 후에 복잡한 기능을 추가해야 함

# Prototype version 1

1. Shared memory enabled된 CycloneDDS를 컨테이너화
	1. Roudi도 컨테이너화
2. CPU 구간 위주로 다음 ROS2 노드 구현(컨테이너 기반):
	1. 이미지 오브젝트 디텍션
	2. 이미지 및 디텍션 결과 합치기
	3. 합쳐진 결과물 시각화
3. 위의 설정으로 한 번에 실행되는지 확인 및 자동화
	1. 아무 것도 설치되지 않은 리눅스 위에서 실행되는지 확인
	2. docker compose 활용하여 자동 launch
4. ros2_benchmark 컨테이너화
	1. hello world 실행
	2. 어떤 유형의 node graph 들에도 적용할 수 있는 방안 고려
	3. docker compose에서 선택적 실행 (performance test 모드)
5. Shared memory configuration 
	1. 데이터 타입 및 hz 및 size에 따라 어떤식으로 설정해야 하는지 파악
	2. 어떤 경우에 에러가 생기는지 파악
	3. 이러한 설정을 보다 더 쉽게 할 수 있는 방안 고려
		1. 테이터 타입, hertz, size 등을 주면 자동으로 계산 및 config 파일 아웃풋
	4. 컨테이너화
6. Performance 테스트 진행
	1. latency
	2. throughput
	3. jitter
	4. 위의 각각의 결괄르 시각화된 자료로 출력되는 기능
	5. 히스토리 저장 기능: DB 또는 CSV포맷 활용
	6. 해당 코드 컨테이너화
	7. Shared memory를 사용할 때와 사용하지 않을 때 비교


# Prototype version 2
1. GPU 연산량 확장
	1. 노드들 중에 GPU에서 구동시키면 빨라질 수 있는 것들 확인
	2. GPU에서 구동되도록 구현
2. 필요한 노드 추가 개발
3. Performance test 진행
	1. CPU위주일 때와 비교 
	2. 두 개의 비교 그래프 및 시각화 자동으로 계산
	3. 아웃풋 생성



# Prototype version 3
다음 사항 체크하기:
1. shared memory 세팅 및 설정 자동화 체크
2. Performance test 세팅 및 설정 자동화 체크



# Prototype version 4
1. GPU pipeline latency 문제 파악
2. lidar latency 문제 최적화 코드

